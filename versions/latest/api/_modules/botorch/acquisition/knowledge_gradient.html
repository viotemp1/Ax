<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Ax · Adaptive Experimentation Platform</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Adaptive Experimentation Platform"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Ax · Adaptive Experimentation Platform"/><meta property="og:type" content="website"/><meta property="og:url" content="https://ax.dev//versions/latest/index.html"/><meta property="og:description" content="Adaptive Experimentation Platform"/><meta property="og:image" content="https://ax.dev//versions/latest/img/ax.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://ax.dev//versions/latest/img/ax.svg"/><link rel="shortcut icon" href="/versions/latest/img/favicon.png"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script>
              (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
              m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
              })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

              ga('create', 'UA-139570076-1', 'auto');
              ga('send', 'pageview');
            </script><script type="text/javascript" src="https://cdn.plot.ly/plotly-latest.min.js"></script><script type="text/javascript" src="/versions/latest/js/plotUtils.js"></script><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="/versions/latest/js/mathjax.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script><script src="https://unpkg.com/vanilla-back-to-top@7.1.14/dist/vanilla-back-to-top.min.js"></script><script>
        document.addEventListener('DOMContentLoaded', function() {
          addBackToTop(
            {"zIndex":100}
          )
        });
        </script><script src="/versions/latest/js/scrollSpy.js"></script><link rel="stylesheet" href="/versions/latest/css/main.css"/><script src="/versions/latest/js/codetabs.js"></script></head><body><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/versions/latest/"><img class="logo" src="/versions/latest/img/ax_lockup_white.svg" alt="Ax"/><h2 class="headerTitleWithLogo">Ax</h2></a><a href="/versions/latest/versions.html"><h3>latest</h3></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/versions/latest/docs/why-ax.html" target="_self">Docs</a></li><li class=""><a href="/versions/latest/tutorials/" target="_self">Tutorials</a></li><li class=""><a href="/versions/latest/api/" target="_self">API</a></li><li class=""><a href="https://github.com/facebook/Ax" target="_self">GitHub</a></li></ul></nav></div></header></div></div><div class="navPusher"><div>
<script type="text/javascript" id="documentation_options" data-url_root="./"
src="/js/documentation_options.js">
</script>
<script type="text/javascript" src="/js/jquery.js"></script>
<script type="text/javascript" src="/js/underscore.js"></script>
<script type="text/javascript" src="/js/doctools.js"></script>
<script type="text/javascript" src="/js/language_data.js"></script>
<script type="text/javascript" src="/js/searchtools.js"></script>
<div class="sphinx"><div class="document">
<div class="documentwrapper">
<div class="bodywrapper">
<div class="body" role="main">
<h1>Source code for botorch.acquisition.knowledge_gradient</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="c1"># Copyright (c) Facebook, Inc. and its affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>

<span class="sa">r</span><span class="sd">"""</span>
<span class="sd">Batch Knowledge Gradient (KG) via one-shot optimization as introduced in</span>
<span class="sd">[Balandat2020botorch]_. For broader discussion of KG see also [Frazier2008knowledge]_</span>
<span class="sd">and [Wu2016parallelkg]_.</span>

<span class="sd">.. [Balandat2020botorch]</span>
<span class="sd">    M. Balandat, B. Karrer, D. R. Jiang, S. Daulton, B. Letham, A. G. Wilson, and</span>
<span class="sd">    E. Bakshy. BoTorch: A Framework for Efficient Monte-Carlo Bayesian Optimization.</span>
<span class="sd">    Advances in Neural Information Processing Systems 33, 2020.</span>

<span class="sd">.. [Frazier2008knowledge]</span>
<span class="sd">    P. Frazier, W. Powell, and S. Dayanik. A Knowledge-Gradient policy for</span>
<span class="sd">    sequential information collection. SIAM Journal on Control and Optimization,</span>
<span class="sd">    2008.</span>

<span class="sd">.. [Wu2016parallelkg]</span>
<span class="sd">    J. Wu and P. Frazier. The parallel knowledge gradient method for batch</span>
<span class="sd">    bayesian optimization. NIPS 2016.</span>
<span class="sd">"""</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Type</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">botorch</span> <span class="kn">import</span> <span class="n">settings</span>
<span class="kn">from</span> <span class="nn">botorch.acquisition.acquisition</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">AcquisitionFunction</span><span class="p">,</span>
    <span class="n">OneShotAcquisitionFunction</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">botorch.acquisition.analytic</span> <span class="kn">import</span> <span class="n">PosteriorMean</span>
<span class="kn">from</span> <span class="nn">botorch.acquisition.cost_aware</span> <span class="kn">import</span> <span class="n">CostAwareUtility</span>
<span class="kn">from</span> <span class="nn">botorch.acquisition.monte_carlo</span> <span class="kn">import</span> <span class="n">MCAcquisitionFunction</span><span class="p">,</span> <span class="n">qSimpleRegret</span>
<span class="kn">from</span> <span class="nn">botorch.acquisition.objective</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">AcquisitionObjective</span><span class="p">,</span>
    <span class="n">MCAcquisitionObjective</span><span class="p">,</span>
    <span class="n">ScalarizedObjective</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">botorch.exceptions.errors</span> <span class="kn">import</span> <span class="n">UnsupportedError</span>
<span class="kn">from</span> <span class="nn">botorch.models.model</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">botorch.sampling.samplers</span> <span class="kn">import</span> <span class="n">MCSampler</span><span class="p">,</span> <span class="n">SobolQMCNormalSampler</span>
<span class="kn">from</span> <span class="nn">botorch.utils.transforms</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">concatenate_pending_points</span><span class="p">,</span>
    <span class="n">match_batch_shape</span><span class="p">,</span>
    <span class="n">t_batch_mode_transform</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span>


<span class="k">class</span> <span class="nc">qKnowledgeGradient</span><span class="p">(</span><span class="n">MCAcquisitionFunction</span><span class="p">,</span> <span class="n">OneShotAcquisitionFunction</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">"""Batch Knowledge Gradient using one-shot optimization.</span>

<span class="sd">    This computes the batch Knowledge Gradient using fantasies for the outer</span>
<span class="sd">    expectation and either the model posterior mean or MC-sampling for the inner</span>
<span class="sd">    expectation.</span>

<span class="sd">    In addition to the design variables, the input `X` also includes variables</span>
<span class="sd">    for the optimal designs for each of the fantasy models. For a fixed number</span>
<span class="sd">    of fantasies, all parts of `X` can be optimized in a "one-shot" fashion.</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">num_fantasies</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span>
        <span class="n">sampler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCSampler</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">objective</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">AcquisitionObjective</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">inner_sampler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCSampler</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">X_pending</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">current_value</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">"""q-Knowledge Gradient (one-shot optimization).</span>

<span class="sd">        Args:</span>
<span class="sd">            model: A fitted model. Must support fantasizing.</span>
<span class="sd">            num_fantasies: The number of fantasy points to use. More fantasy</span>
<span class="sd">                points result in a better approximation, at the expense of</span>
<span class="sd">                memory and wall time. Unused if `sampler` is specified.</span>
<span class="sd">            sampler: The sampler used to sample fantasy observations. Optional</span>
<span class="sd">                if `num_fantasies` is specified.</span>
<span class="sd">            objective: The objective under which the samples are evaluated. If</span>
<span class="sd">                `None` or a ScalarizedObjective, then the analytic posterior mean</span>
<span class="sd">                is used, otherwise the objective is MC-evaluated (using</span>
<span class="sd">                inner_sampler).</span>
<span class="sd">            inner_sampler: The sampler used for inner sampling. Ignored if the</span>
<span class="sd">                objective is `None` or a ScalarizedObjective.</span>
<span class="sd">            X_pending: A `m x d`-dim Tensor of `m` design points that have</span>
<span class="sd">                points that have been submitted for function evaluation</span>
<span class="sd">                but have not yet been evaluated.</span>
<span class="sd">            current_value: The current value, i.e. the expected best objective</span>
<span class="sd">                given the observed points `D`. If omitted, forward will not</span>
<span class="sd">                return the actual KG value, but the expected best objective</span>
<span class="sd">                given the data set `D u X`.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="n">sampler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">num_fantasies</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">"Must specify `num_fantasies` if no `sampler` is provided."</span>
                <span class="p">)</span>
            <span class="c1"># base samples should be fixed for joint optimization over X, X_fantasies</span>
            <span class="n">sampler</span> <span class="o">=</span> <span class="n">SobolQMCNormalSampler</span><span class="p">(</span>
                <span class="n">num_samples</span><span class="o">=</span><span class="n">num_fantasies</span><span class="p">,</span> <span class="n">resample</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">collapse_batch_dims</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">num_fantasies</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">sampler</span><span class="o">.</span><span class="n">sample_shape</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">num_fantasies</span><span class="p">]):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">"The sampler shape must match num_fantasies=</span><span class="si">{</span><span class="n">num_fantasies</span><span class="si">}</span><span class="s2">."</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">num_fantasies</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">sample_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MCAcquisitionFunction</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
        <span class="c1"># if not explicitly specified, we use the posterior mean for linear objs</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">MCAcquisitionObjective</span><span class="p">)</span> <span class="ow">and</span> <span class="n">inner_sampler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">inner_sampler</span> <span class="o">=</span> <span class="n">SobolQMCNormalSampler</span><span class="p">(</span>
                <span class="n">num_samples</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">resample</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">collapse_batch_dims</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">objective</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">model</span><span class="o">.</span><span class="n">num_outputs</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">UnsupportedError</span><span class="p">(</span>
                <span class="s2">"Must specify an objective when using a multi-output model."</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span> <span class="o">=</span> <span class="n">sampler</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">objective</span> <span class="o">=</span> <span class="n">objective</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_X_pending</span><span class="p">(</span><span class="n">X_pending</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inner_sampler</span> <span class="o">=</span> <span class="n">inner_sampler</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_fantasies</span> <span class="o">=</span> <span class="n">num_fantasies</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_value</span> <span class="o">=</span> <span class="n">current_value</span>

    <span class="nd">@t_batch_mode_transform</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">"""Evaluate qKnowledgeGradient on the candidate set `X`.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `b x (q + num_fantasies) x d` Tensor with `b` t-batches of</span>
<span class="sd">                `q + num_fantasies` design points each. We split this X tensor</span>
<span class="sd">                into two parts in the `q` dimension (`dim=-2`). The first `q`</span>
<span class="sd">                are the q-batch of design points and the last num_fantasies are</span>
<span class="sd">                the current solutions of the inner optimization problem.</span>

<span class="sd">                `X_fantasies = X[..., -num_fantasies:, :]`</span>
<span class="sd">                `X_fantasies.shape = b x num_fantasies x d`</span>

<span class="sd">                `X_actual = X[..., :-num_fantasies, :]`</span>
<span class="sd">                `X_actual.shape = b x q x d`</span>

<span class="sd">        Returns:</span>
<span class="sd">            A Tensor of shape `b`. For t-batch b, the q-KG value of the design</span>
<span class="sd">                `X_actual[b]` is averaged across the fantasy models, where</span>
<span class="sd">                `X_fantasies[b, i]` is chosen as the final selection for the</span>
<span class="sd">                `i`-th fantasy model.</span>
<span class="sd">                NOTE: If `current_value` is not provided, then this is not the</span>
<span class="sd">                true KG value of `X_actual[b]`, and `X_fantasies[b, : ]` must be</span>
<span class="sd">                maximized at fixed `X_actual[b]`.</span>
<span class="sd">        """</span>
        <span class="n">X_actual</span><span class="p">,</span> <span class="n">X_fantasies</span> <span class="o">=</span> <span class="n">_split_fantasy_points</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">n_f</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_fantasies</span><span class="p">)</span>

        <span class="c1"># We only concatenate X_pending into the X part after splitting</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_pending</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">X_actual</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                <span class="p">[</span><span class="n">X_actual</span><span class="p">,</span> <span class="n">match_batch_shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_pending</span><span class="p">,</span> <span class="n">X_actual</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span>
            <span class="p">)</span>

        <span class="c1"># construct the fantasy model of shape `num_fantasies x b`</span>
        <span class="n">fantasy_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fantasize</span><span class="p">(</span>
            <span class="n">X</span><span class="o">=</span><span class="n">X_actual</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="p">,</span> <span class="n">observation_noise</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

        <span class="c1"># get the value function</span>
        <span class="n">value_function</span> <span class="o">=</span> <span class="n">_get_value_function</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">fantasy_model</span><span class="p">,</span> <span class="n">objective</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">inner_sampler</span>
        <span class="p">)</span>

        <span class="c1"># make sure to propagate gradients to the fantasy model train inputs</span>
        <span class="k">with</span> <span class="n">settings</span><span class="o">.</span><span class="n">propagate_grads</span><span class="p">(</span><span class="kc">True</span><span class="p">):</span>
            <span class="n">values</span> <span class="o">=</span> <span class="n">value_function</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_fantasies</span><span class="p">)</span>  <span class="c1"># num_fantasies x b</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">values</span> <span class="o">=</span> <span class="n">values</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_value</span>

        <span class="c1"># return average over the fantasy samples</span>
        <span class="k">return</span> <span class="n">values</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="nd">@concatenate_pending_points</span>
    <span class="nd">@t_batch_mode_transform</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">bounds</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">"""Evaluate qKnowledgeGradient on the candidate set `X_actual` by</span>
<span class="sd">        solving the inner optimization problem.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `b x q x d` Tensor with `b` t-batches of `q` design points</span>
<span class="sd">                each. Unlike `forward()`, this does not include solutions of the</span>
<span class="sd">                inner optimization problem.</span>
<span class="sd">            bounds: A `2 x d` tensor of lower and upper bounds for each column of</span>
<span class="sd">                the solutions to the inner problem.</span>
<span class="sd">            kwargs: Additional keyword arguments. This includes the options for</span>
<span class="sd">                optimization of the inner problem, i.e. `num_restarts`, `raw_samples`,</span>
<span class="sd">                an `options` dictionary to be passed on to the optimization helpers, and</span>
<span class="sd">                a `scipy_options` dictionary to be passed to `scipy.minimize`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A Tensor of shape `b`. For t-batch b, the q-KG value of the design</span>
<span class="sd">                `X[b]` is averaged across the fantasy models.</span>
<span class="sd">                NOTE: If `current_value` is not provided, then this is not the</span>
<span class="sd">                true KG value of `X[b]`.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">"expand"</span><span class="p">):</span>
            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="c1"># construct the fantasy model of shape `num_fantasies x b`</span>
        <span class="n">fantasy_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fantasize</span><span class="p">(</span>
            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="p">,</span> <span class="n">observation_noise</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

        <span class="c1"># get the value function</span>
        <span class="n">value_function</span> <span class="o">=</span> <span class="n">_get_value_function</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">fantasy_model</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">inner_sampler</span><span class="p">,</span>
            <span class="n">project</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">"project"</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="kn">from</span> <span class="nn">botorch.generation.gen</span> <span class="kn">import</span> <span class="n">gen_candidates_scipy</span>

        <span class="c1"># optimize the inner problem</span>
        <span class="kn">from</span> <span class="nn">botorch.optim.initializers</span> <span class="kn">import</span> <span class="n">gen_value_function_initial_conditions</span>

        <span class="n">initial_conditions</span> <span class="o">=</span> <span class="n">gen_value_function_initial_conditions</span><span class="p">(</span>
            <span class="n">acq_function</span><span class="o">=</span><span class="n">value_function</span><span class="p">,</span>
            <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span>
            <span class="n">num_restarts</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"num_restarts"</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span>
            <span class="n">raw_samples</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"raw_samples"</span><span class="p">,</span> <span class="mi">1024</span><span class="p">),</span>
            <span class="n">current_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="o">**</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"options"</span><span class="p">,</span> <span class="p">{}),</span> <span class="o">**</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"scipy_options"</span><span class="p">,</span> <span class="p">{})},</span>
        <span class="p">)</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">values</span> <span class="o">=</span> <span class="n">gen_candidates_scipy</span><span class="p">(</span>
            <span class="n">initial_conditions</span><span class="o">=</span><span class="n">initial_conditions</span><span class="p">,</span>
            <span class="n">acquisition_function</span><span class="o">=</span><span class="n">value_function</span><span class="p">,</span>
            <span class="n">lower_bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">upper_bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
            <span class="n">options</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"scipy_options"</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="c1"># get the maximizer for each batch</span>
        <span class="n">values</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">values</span> <span class="o">=</span> <span class="n">values</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_value</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">"cost_aware_utility"</span><span class="p">):</span>
            <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost_aware_utility</span><span class="p">(</span>
                <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">deltas</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cost_sampler</span>
            <span class="p">)</span>
        <span class="c1"># return average over the fantasy samples</span>
        <span class="k">return</span> <span class="n">values</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_augmented_q_batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">"""Get augmented q batch size for one-shot optimization.</span>

<span class="sd">        Args:</span>
<span class="sd">            q: The number of candidates to consider jointly.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The augmented size for one-shot optimization (including variables</span>
<span class="sd">            parameterizing the fantasy solutions).</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="n">q</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_fantasies</span>

    <span class="k">def</span> <span class="nf">extract_candidates</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_full</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">"""We only return X as the set of candidates post-optimization.</span>

<span class="sd">        Args:</span>
<span class="sd">            X_full: A `b x (q + num_fantasies) x d`-dim Tensor with `b`</span>
<span class="sd">                t-batches of `q + num_fantasies` design points each.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `b x q x d`-dim Tensor with `b` t-batches of `q` design points each.</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="n">X_full</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">num_fantasies</span><span class="p">,</span> <span class="p">:]</span>


<span class="k">class</span> <span class="nc">qMultiFidelityKnowledgeGradient</span><span class="p">(</span><span class="n">qKnowledgeGradient</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">"""Batch Knowledge Gradient for multi-fidelity optimization.</span>

<span class="sd">    A version of `qKnowledgeGradient` that supports multi-fidelity optimization</span>
<span class="sd">    via a `CostAwareUtility` and the `project` and `expand` operators. If none</span>
<span class="sd">    of these are set, this acquisition function reduces to `qKnowledgeGradient`.</span>
<span class="sd">    Through `valfunc_cls` and `valfunc_argfac`, this can be changed into a custom</span>
<span class="sd">    multifidelity acquisition function (it is only KG if the terminal value is</span>
<span class="sd">    computed using a posterior mean).</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">num_fantasies</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span>
        <span class="n">sampler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCSampler</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">objective</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">AcquisitionObjective</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">inner_sampler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCSampler</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">X_pending</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">current_value</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cost_aware_utility</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">CostAwareUtility</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">project</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span>
        <span class="n">expand</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span>
        <span class="n">valfunc_cls</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Type</span><span class="p">[</span><span class="n">AcquisitionFunction</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">valfunc_argfac</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Model</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">"""Multi-Fidelity q-Knowledge Gradient (one-shot optimization).</span>

<span class="sd">        Args:</span>
<span class="sd">            model: A fitted model. Must support fantasizing.</span>
<span class="sd">            num_fantasies: The number of fantasy points to use. More fantasy</span>
<span class="sd">                points result in a better approximation, at the expense of</span>
<span class="sd">                memory and wall time. Unused if `sampler` is specified.</span>
<span class="sd">            sampler: The sampler used to sample fantasy observations. Optional</span>
<span class="sd">                if `num_fantasies` is specified.</span>
<span class="sd">            objective: The objective under which the samples are evaluated. If</span>
<span class="sd">                `None` or a ScalarizedObjective, then the analytic posterior mean</span>
<span class="sd">                is used, otherwise the objective is MC-evaluated (using</span>
<span class="sd">                inner_sampler).</span>
<span class="sd">            inner_sampler: The sampler used for inner sampling. Ignored if the</span>
<span class="sd">                objective is `None` or a ScalarizedObjective.</span>
<span class="sd">            X_pending: A `m x d`-dim Tensor of `m` design points that have</span>
<span class="sd">                points that have been submitted for function evaluation</span>
<span class="sd">                but have not yet been evaluated.</span>
<span class="sd">            current_value: The current value, i.e. the expected best objective</span>
<span class="sd">                given the observed points `D`. If omitted, forward will not</span>
<span class="sd">                return the actual KG value, but the expected best objective</span>
<span class="sd">                given the data set `D u X`.</span>
<span class="sd">            cost_aware_utility: A CostAwareUtility computing the cost-transformed</span>
<span class="sd">                utility from a candidate set and samples of increases in utility.</span>
<span class="sd">            project: A callable mapping a `batch_shape x q x d` tensor of design</span>
<span class="sd">                points to a tensor with shape `batch_shape x q_term x d` projected</span>
<span class="sd">                to the desired target set (e.g. the target fidelities in case of</span>
<span class="sd">                multi-fidelity optimization). For the basic case, `q_term = q`.</span>
<span class="sd">            expand: A callable mapping a `batch_shape x q x d` input tensor to</span>
<span class="sd">                a `batch_shape x (q + q_e)' x d`-dim output tensor, where the</span>
<span class="sd">                `q_e` additional points in each q-batch correspond to</span>
<span class="sd">                additional ("trace") observations.</span>
<span class="sd">            valfunc_cls: An acquisition function class to be used as the terminal</span>
<span class="sd">                value function.</span>
<span class="sd">            valfunc_argfac: An argument factory, i.e. callable that maps a `Model`</span>
<span class="sd">                to a dictionary of kwargs for the terminal value function (e.g.</span>
<span class="sd">                `best_f` for `ExpectedImprovement`).</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="n">current_value</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">cost_aware_utility</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">UnsupportedError</span><span class="p">(</span>
                <span class="s2">"Cost-aware KG requires current_value to be specified."</span>
            <span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">num_fantasies</span><span class="o">=</span><span class="n">num_fantasies</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">inner_sampler</span><span class="o">=</span><span class="n">inner_sampler</span><span class="p">,</span>
            <span class="n">X_pending</span><span class="o">=</span><span class="n">X_pending</span><span class="p">,</span>
            <span class="n">current_value</span><span class="o">=</span><span class="n">current_value</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cost_aware_utility</span> <span class="o">=</span> <span class="n">cost_aware_utility</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">project</span> <span class="o">=</span> <span class="n">project</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">expand</span> <span class="o">=</span> <span class="n">expand</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cost_sampler</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valfunc_cls</span> <span class="o">=</span> <span class="n">valfunc_cls</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valfunc_argfac</span> <span class="o">=</span> <span class="n">valfunc_argfac</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">cost_sampler</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cost_sampler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Note: Using the deepcopy here is essential. Removing this poses a</span>
            <span class="c1"># problem if the base model and the cost model have a different number</span>
            <span class="c1"># of outputs or test points (this would be caused by expand), as this</span>
            <span class="c1"># would trigger re-sampling the base samples in the fantasy sampler.</span>
            <span class="c1"># By cloning the sampler here, the right thing will happen if the</span>
            <span class="c1"># the sizes are compatible, if they are not this will result in</span>
            <span class="c1"># samples being drawn using different base samples, but it will at</span>
            <span class="c1"># least avoid changing state of the fantasy sampler.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_cost_sampler</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cost_sampler</span>

    <span class="nd">@t_batch_mode_transform</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">"""Evaluate qMultiFidelityKnowledgeGradient on the candidate set `X`.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `b x (q + num_fantasies) x d` Tensor with `b` t-batches of</span>
<span class="sd">                `q + num_fantasies` design points each. We split this X tensor</span>
<span class="sd">                into two parts in the `q` dimension (`dim=-2`). The first `q`</span>
<span class="sd">                are the q-batch of design points and the last num_fantasies are</span>
<span class="sd">                the current solutions of the inner optimization problem.</span>

<span class="sd">                `X_fantasies = X[..., -num_fantasies:, :]`</span>
<span class="sd">                `X_fantasies.shape = b x num_fantasies x d`</span>

<span class="sd">                `X_actual = X[..., :-num_fantasies, :]`</span>
<span class="sd">                `X_actual.shape = b x q x d`</span>

<span class="sd">                In addition, `X` may be augmented with fidelity parameteres as</span>
<span class="sd">                part of thee `d`-dimension. Projecting fidelities to the target</span>
<span class="sd">                fidelity is handled by `project`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A Tensor of shape `b`. For t-batch b, the q-KG value of the design</span>
<span class="sd">                `X_actual[b]` is averaged across the fantasy models, where</span>
<span class="sd">                `X_fantasies[b, i]` is chosen as the final selection for the</span>
<span class="sd">                `i`-th fantasy model.</span>
<span class="sd">                NOTE: If `current_value` is not provided, then this is not the</span>
<span class="sd">                true KG value of `X_actual[b]`, and `X_fantasies[b, : ]` must be</span>
<span class="sd">                maximized at fixed `X_actual[b]`.</span>
<span class="sd">        """</span>
        <span class="n">X_actual</span><span class="p">,</span> <span class="n">X_fantasies</span> <span class="o">=</span> <span class="n">_split_fantasy_points</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">n_f</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_fantasies</span><span class="p">)</span>

        <span class="c1"># We only concatenate X_pending into the X part after splitting</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_pending</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">X_eval</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                <span class="p">[</span><span class="n">X_actual</span><span class="p">,</span> <span class="n">match_batch_shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_pending</span><span class="p">,</span> <span class="n">X_actual</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X_eval</span> <span class="o">=</span> <span class="n">X_actual</span>

        <span class="c1"># construct the fantasy model of shape `num_fantasies x b`</span>
        <span class="c1"># expand X (to potentially add trace observations)</span>
        <span class="n">fantasy_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fantasize</span><span class="p">(</span>
            <span class="n">X</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">X_eval</span><span class="p">),</span> <span class="n">sampler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="p">,</span> <span class="n">observation_noise</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
        <span class="c1"># get the value function</span>
        <span class="n">value_function</span> <span class="o">=</span> <span class="n">_get_value_function</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">fantasy_model</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">inner_sampler</span><span class="p">,</span>
            <span class="n">project</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">project</span><span class="p">,</span>
            <span class="n">valfunc_cls</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">valfunc_cls</span><span class="p">,</span>
            <span class="n">valfunc_argfac</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">valfunc_argfac</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># make sure to propagate gradients to the fantasy model train inputs</span>
        <span class="c1"># project the fantasy points</span>
        <span class="k">with</span> <span class="n">settings</span><span class="o">.</span><span class="n">propagate_grads</span><span class="p">(</span><span class="kc">True</span><span class="p">):</span>
            <span class="n">values</span> <span class="o">=</span> <span class="n">value_function</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_fantasies</span><span class="p">)</span>  <span class="c1"># num_fantasies x b</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">values</span> <span class="o">=</span> <span class="n">values</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_value</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost_aware_utility</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost_aware_utility</span><span class="p">(</span>
                <span class="n">X</span><span class="o">=</span><span class="n">X_actual</span><span class="p">,</span> <span class="n">deltas</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cost_sampler</span>
            <span class="p">)</span>

        <span class="c1"># return average over the fantasy samples</span>
        <span class="k">return</span> <span class="n">values</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">ProjectedAcquisitionFunction</span><span class="p">(</span><span class="n">AcquisitionFunction</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">"""</span>
<span class="sd">    Defines a wrapper around  an `AcquisitionFunction` that incorporates the project</span>
<span class="sd">    operator. Typically used to handle value functions in look-ahead methods.</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">base_value_function</span><span class="p">:</span> <span class="n">AcquisitionFunction</span><span class="p">,</span>
        <span class="n">project</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">base_value_function</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_value_function</span> <span class="o">=</span> <span class="n">base_value_function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">project</span> <span class="o">=</span> <span class="n">project</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">objective</span> <span class="o">=</span> <span class="n">base_value_function</span><span class="o">.</span><span class="n">objective</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">base_value_function</span><span class="p">,</span> <span class="s2">"sampler"</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_value_function</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">project</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">_get_value_function</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
    <span class="n">objective</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">MCAcquisitionObjective</span><span class="p">,</span> <span class="n">ScalarizedObjective</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">sampler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCSampler</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">project</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">valfunc_cls</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Type</span><span class="p">[</span><span class="n">AcquisitionFunction</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">valfunc_argfac</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Model</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AcquisitionFunction</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">"""Construct value function (i.e. inner acquisition function)."""</span>
    <span class="k">if</span> <span class="n">valfunc_cls</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">common_kwargs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"model"</span><span class="p">:</span> <span class="n">model</span><span class="p">,</span> <span class="s2">"objective"</span><span class="p">:</span> <span class="n">objective</span><span class="p">}</span>
        <span class="k">if</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">valfunc_cls</span><span class="p">,</span> <span class="n">MCAcquisitionFunction</span><span class="p">):</span>
            <span class="n">common_kwargs</span><span class="p">[</span><span class="s2">"sampler"</span><span class="p">]</span> <span class="o">=</span> <span class="n">sampler</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="n">valfunc_argfac</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span> <span class="k">if</span> <span class="n">valfunc_argfac</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
        <span class="n">base_value_function</span> <span class="o">=</span> <span class="n">valfunc_cls</span><span class="p">(</span><span class="o">**</span><span class="n">common_kwargs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">MCAcquisitionObjective</span><span class="p">):</span>
            <span class="n">base_value_function</span> <span class="o">=</span> <span class="n">qSimpleRegret</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span> <span class="n">objective</span><span class="o">=</span><span class="n">objective</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">base_value_function</span> <span class="o">=</span> <span class="n">PosteriorMean</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">project</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">base_value_function</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ProjectedAcquisitionFunction</span><span class="p">(</span>
            <span class="n">base_value_function</span><span class="o">=</span><span class="n">base_value_function</span><span class="p">,</span>
            <span class="n">project</span><span class="o">=</span><span class="n">project</span><span class="p">,</span>
        <span class="p">)</span>


<span class="k">def</span> <span class="nf">_split_fantasy_points</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">n_f</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
    <span class="sa">r</span><span class="sd">"""Split a one-shot optimization input into actual and fantasy points</span>

<span class="sd">    Args:</span>
<span class="sd">        X: A `batch_shape x (q + n_f) x d`-dim tensor of actual and fantasy</span>
<span class="sd">            points</span>

<span class="sd">    Returns:</span>
<span class="sd">        2-element tuple containing</span>

<span class="sd">        - A `batch_shape x q x d`-dim tensor `X_actual` of input candidates.</span>
<span class="sd">        - A `n_f x batch_shape x 1 x d`-dim tensor `X_fantasies` of fantasy</span>
<span class="sd">            points, where `X_fantasies[i, batch_idx]` is the i-th fantasy point</span>
<span class="sd">            associated with the batch indexed by `batch_idx`.</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">n_f</span> <span class="o">&gt;</span> <span class="n">X</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">"n_f (</span><span class="si">{</span><span class="n">n_f</span><span class="si">}</span><span class="s2">) must be less than the q-batch dimension of X (</span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">)"</span>
        <span class="p">)</span>
    <span class="n">split_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="n">X</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">n_f</span><span class="p">,</span> <span class="n">n_f</span><span class="p">]</span>
    <span class="n">X_actual</span><span class="p">,</span> <span class="n">X_fantasies</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">split_sizes</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
    <span class="c1"># X_fantasies is b x num_fantasies x d, needs to be num_fantasies x b x 1 x d</span>
    <span class="c1"># for batch mode evaluation with batch shape num_fantasies x b.</span>
    <span class="c1"># b x num_fantasies x d --&gt; num_fantasies x b x d</span>
    <span class="n">X_fantasies</span> <span class="o">=</span> <span class="n">X_fantasies</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">*</span><span class="nb">range</span><span class="p">(</span><span class="n">X_fantasies</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="mi">2</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># num_fantasies x b x 1 x d</span>
    <span class="n">X_fantasies</span> <span class="o">=</span> <span class="n">X_fantasies</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X_actual</span><span class="p">,</span> <span class="n">X_fantasies</span>
</pre></div>
</div>
</div>
</div>
<div aria-label="main navigation" class="sphinxsidebar" role="navigation">
<div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../index.html">Ax</a></h1>
<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../ax.html">ax</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../benchmark.html">ax.benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../core.html">ax.core</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../exceptions.html">ax.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../metrics.html">ax.metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../modelbridge.html">ax.modelbridge</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models.html">ax.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../plot.html">ax.plot</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../runners.html">ax.runners</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../service.html">ax.service</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../storage.html">ax.storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../utils.html">ax.utils</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
<li><a href="../../../index.html">Documentation overview</a><ul>
<li><a href="../../index.html">Module code</a><ul>
</ul></li>
</ul></li>
</ul>
</div>
<div id="searchbox" role="search" style="display: none">
<h3 id="searchlabel">Quick search</h3>
<div class="searchformwrapper">
<form action="../../../search.html" class="search" method="get">
<input aria-labelledby="searchlabel" name="q" type="text"/>
<input type="submit" value="Go"/>
</form>
</div>
</div>
<script>$('#searchbox').show(0);</script>
</div>
</div>
<div class="clearer"></div>
</div></div></div><footer class="nav-footer" id="footer"><section class="sitemap"><div class="footerSection"><h5>Legal</h5><a href="https://opensource.facebook.com/legal/privacy/" target="_blank" rel="noreferrer noopener">Privacy</a><a href="https://opensource.facebook.com/legal/terms/" target="_blank" rel="noreferrer noopener">Terms</a></div></section><a href="https://code.facebook.com/projects/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/versions/latest/img/oss_logo.png" alt="Facebook Open Source" width="170" height="45"/></a><section class="copyright">Copyright © 2021 Facebook Inc.</section></footer></div></body></html>